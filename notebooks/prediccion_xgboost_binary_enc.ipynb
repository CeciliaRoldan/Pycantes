{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ba4897b401c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodsel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#pandas libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.model_selection as modsel\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "%run \"../notebooks/cargar_df.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.Stage.isin(['Closed Won', 'Closed Lost'])].copy()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo con los registros con la oportunidad terminada\n",
    "train.Stage.replace({'Closed Won': 1, 'Closed Lost': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cantidad de opportunity_id de train:',train.Opportunity_ID.nunique())\n",
    "print('Cantidad de opportunity_id de test:',test.Opportunity_ID.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junto el set de train y test en un nuevo data frame data\n",
    "data = pd.concat([train.drop('Stage', axis=1), test])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armo otro data frame con las columnas que no cambian de valor en la misma oportunidad con distintas Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data.groupby('Opportunity_ID').agg(\\\n",
    "    {'Region':'first',\n",
    "     'Territory':'first',\n",
    "     'Pricing, Delivery_Terms_Quote_Appr':'first',\n",
    "     'Pricing, Delivery_Terms_Approved':'first',\n",
    "     'Bureaucratic_Code_0_Approval':'first',\n",
    "     'Bureaucratic_Code_0_Approved':'first',\n",
    "     'Bureaucratic_Code':'first',\n",
    "     'Account_Created_Date':'first',\n",
    "     'Source ':'first',\n",
    "     'Billing_Country':'first',\n",
    "     'Account_Name':'first',\n",
    "     'Opportunity_Name':'first',\n",
    "     'Account_Owner':'first',\n",
    "     'Opportunity_Owner':'first',\n",
    "     'Account_Type':'first',\n",
    "     'Opportunity_Type':'first',\n",
    "     'Quote_Type':'first',\n",
    "     'Delivery_Terms':'first',\n",
    "     'Opportunity_Created_Date':'first',\n",
    "     'Brand':'first',\n",
    "     'Product_Type':'first',\n",
    "     'Size':'first',\n",
    "     'Product_Category_B':'first',\n",
    "     'Price':'first',\n",
    "     'Currency':'first',\n",
    "     'Quote_Expiry_Date':'first',\n",
    "     'Last_Modified_Date':'first',\n",
    "     'Last_Modified_By':'first',\n",
    "     'ASP_Currency':'first',\n",
    "     'Total_Amount_Currency':'first',\n",
    "     'Total_Taxable_Amount_Currency':'first',\n",
    "     'Total_Taxable_Amount':'first'}).reset_index()\n",
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({'Opportunity_ID':grouped_data.Opportunity_ID})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Pricing, Delivery_Terms_Quote_Appr'] = grouped_data['Pricing, Delivery_Terms_Quote_Appr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Pricing, Delivery_Terms_Approved'] = grouped_data['Pricing, Delivery_Terms_Approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_ok = grouped_data.agg(lambda x: int(x['Pricing, Delivery_Terms_Quote_Appr'] \\\n",
    "              == x['Pricing, Delivery_Terms_Approved']), axis = 1)\n",
    "pricing_ok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binaria, es 1 si se necesitaba aprobaci贸n y se aprob贸 o si no la necesitaba\n",
    "# Es 0 si necesitaba aprobacion y no se aprobo\n",
    "X['pricing_aprobada'] = pricing_ok\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego features binarios Bureaucratic_Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Bureaucratic_Code_0_Approval'] = grouped_data['Bureaucratic_Code_0_Approval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Bureaucratic_Code_0_Approved'] = grouped_data['Bureaucratic_Code_0_Approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureaucratic_ok = grouped_data.agg(lambda x: int(x['Bureaucratic_Code_0_Approval'] \\\n",
    "              == x['Bureaucratic_Code_0_Approved']), axis = 1)\n",
    "bureaucratic_ok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binaria, es 1 si se necesitaba aprobaci贸n y se aprob贸 o si no la necesitaba\n",
    "# Si necesitaba aprobacion y no se aprobo es 0\n",
    "X['bureaucratic_aprobada'] = bureaucratic_ok\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: binaria 1 si hay mas de 1 ID de la oportunidad, 0 si hay solo un registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = data.groupby('Opportunity_ID').ID.count()\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = (ids != 1).astype('int8').reset_index()\n",
    "group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['amount_ids'] = group1.ID\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: menor anio de creacion de oportunidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Opportunity_ID').Delivery_Year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = data.groupby('Opportunity_ID').Delivery_Year.min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['min_year'] = min_year.Delivery_Year\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: cantidad de dias activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo la cantidad de dias activos que tuvo cada oportunidad\n",
    "days = grouped_data['Last_Modified_Date'] - grouped_data['Opportunity_Created_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days.dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['active_days'] = days.dt.days\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me fijo cuantos null hay por columnas\n",
    "print('Cantidad de nulos por columna')\n",
    "grouped_data.replace({'None':np.NaN}).isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paso las columnas con muchos nulos a binario:\n",
    "    1 si tiene valor y 0 si es nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['has_source'] = (grouped_data['Source '] == 'None').astype('int8')\n",
    "X['has_brand'] = (grouped_data['Brand'] == 'None').astype('int8')\n",
    "X['has_product_Type'] = (grouped_data['Product_Type'] == 'None').astype('int8')\n",
    "X['has_size'] = (grouped_data['Size'] == 'None').astype('int8')\n",
    "X['has_product_Category_B'] = (grouped_data['Product_Category_B'] == 'None').astype('int8')\n",
    "X['has_price'] = (grouped_data['Price'] == 'None').astype('int8')\n",
    "X['has_currency'] = (grouped_data['Currency'] == 'None').astype('int8')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego feature, el numero de delivery quarter\n",
    "\n",
    "first_quarter = data.groupby('Opportunity_ID').Delivery_Quarter.first()\\\n",
    "                     .agg(lambda x: x[1:2]).astype('int8')\\\n",
    "                     .reset_index().drop('Opportunity_ID', axis=1)\n",
    "\n",
    "X = pd.concat([X, first_quarter], axis = 1, sort=False)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: menor mes y anio de la columna Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month'] = data.Month.dt.month\n",
    "data['year'] = data.Month.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = data.groupby('Opportunity_ID').agg({'month':'min', 'year':'min'})\\\n",
    "        .reset_index().drop('Opportunity_ID', axis=1)\n",
    "X = pd.concat([X, u], axis = 1, sort=False)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data['Territory'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformo las columnas categoricas con binary encoder\n",
    "\n",
    "categorical_cols = []\n",
    "\n",
    "for col in grouped_data.columns:\n",
    "    if (grouped_data[col].dtype == 'O'):\n",
    "        categorical_cols.append(col)\n",
    "        print(col)\n",
    "\n",
    "print()\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    X[col] = grouped_data[col]\n",
    "\n",
    "encoder = ce.BinaryEncoder(cols = categorical_cols)\n",
    "X = encoder.fit_transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino los outliers de las columnas ASP y ASP_Converted\n",
    "data_asp_mean = data[data.ASP <= 10].ASP.mean()\n",
    "outliers =  data.ASP <= 10\n",
    "data.ASP = data.ASP.where(outliers, data_asp_mean)\n",
    "\n",
    "data_asp_mean = data[data['ASP_(converted)'] <= 10]['ASP_(converted)'].mean()\n",
    "outliers =  data['ASP_(converted)'] <= 10\n",
    "data['ASP_(converted)'] = data['ASP_(converted)'].where(outliers, data_asp_mean)\n",
    "\n",
    "\n",
    "# Del Tp1\n",
    "\n",
    "# https://data.oecd.org/conversion/exchange-rates.htm\n",
    "price_usd_convertion_by_year = {\n",
    "    'EUR': {2016: 0.940, 2017: 0.923, 2018: 0.848, 2019: 0.893, 2020: 0.860},\n",
    "    'JPY': {2016: 113.138, 2017: 116.667, 2018: 110.424, 2019: 109.008, 2020: 104.66},\n",
    "    'AUD': {2016: 1.400, 2017: 1.358, 2018: 1.340, 2019: 1.439, 2020: 1.420},\n",
    "    'GBP': {2016: 0.770, 2017: 0.808, 2018: 0.750, 2019: 0.784, 2020: 0.770},\n",
    "    'USD': {2016: 1, 2017: 1, 2018: 1, 2019: 1, 2020: 1}\n",
    "}\n",
    "\n",
    "def get_convertion_usd(x):\n",
    "    currency = x['Total_Amount_Currency']\n",
    "    year = pd.to_datetime(x['Month']).year\n",
    "    return price_usd_convertion_by_year[currency][year]\n",
    "    \n",
    "data['Total_Amount_USD'] = data['Total_Amount'] / data.apply(lambda x: get_convertion_usd(x), axis=1)\n",
    "\n",
    "data['Total_Amount_USD'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego como feature el promedio de asp\n",
    "u = data.groupby('Opportunity_ID').ASP.mean()\\\n",
    "        .reset_index().drop('Opportunity_ID', axis=1)\n",
    "X = pd.concat([X,u], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego como feature el promedio de asp converted\n",
    "u = data.groupby('Opportunity_ID')['ASP_(converted)'].mean()\\\n",
    "        .reset_index().drop('Opportunity_ID', axis=1)\n",
    "X = pd.concat([X,u], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego como feature el promedio de Total_Amount_USD\n",
    "u = data.groupby('Opportunity_ID')['Total_Amount_USD'].mean()\\\n",
    "        .reset_index().drop('Opportunity_ID', axis=1)\n",
    "X = pd.concat([X,u], axis=1, sort=False)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mean = X.Total_Amount_USD.mean()\n",
    "total_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.replace({np.NaN: total_mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train.Opportunity_ID.unique()\n",
    "trainX = X[X['Opportunity_ID'].isin(train_ids)]\n",
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.groupby('Opportunity_ID')['Stage'].min()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y.index != trainX.Opportunity_ID).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test.Opportunity_ID.unique()\n",
    "testX = X[X['Opportunity_ID'].isin(test_ids)]\n",
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(trainX, y, on='Opportunity_ID').to_csv(\\\n",
    "    '../files_csv/train_173_features_bin_encoding', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.to_csv('../files_csv/test_173_features_bin_encoding', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(trainX.drop(['Opportunity_ID'], axis=1), y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo el error\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(trainX, y, test_size=0.2, random_state=123)\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective = 'binary:logistic', \\\n",
    "                           colsample_bytree = 0.3, \\\n",
    "                           learning_rate = 0.1, \\\n",
    "                           max_depth = 5, \\\n",
    "                           alpha = 10, \\\n",
    "                           n_estimators = 10, \\\n",
    "                           eval_metric='logloss')\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "preds = xgb_reg.predict(X_test)\n",
    "ll = log_loss(y_test, preds, normalize=True)\n",
    "print(\"Log Loss: %f\" % (ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "xgb_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame({'feature':X_train.columns, 'value':xgb_reg.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = p.sort_values('value').nlargest(50, 'value')\n",
    "\n",
    "plt.bar(df.feature, df.value, )\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia Features con XGBRegressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = p.sort_values('value').nsmallest(X.shape[1]-50, 'value')\n",
    "\n",
    "plt.bar(df.feature, df.value)\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia Features con XGBRegressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state=1, n_estimators=5)\n",
    "\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "preds = rf_model.predict(X_test)\n",
    "\n",
    "loss = log_loss(y_test, preds)\n",
    "print(\"Loss: %f\" % (loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPO5ApzhYH1j"
   },
   "outputs": [],
   "source": [
    "tree0 = rf_model.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame({'feature':X_train.columns, 'value':tree0.feature_importances_})\n",
    "p = p.sort_values('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(p.feature, p.value)\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia Features con Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state=1, n_estimators=5)\n",
    "\n",
    "rf_model.fit(trainX, y)\n",
    "preds = rf_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = pd.DataFrame({'Opportunity_ID':testX.Opportunity_ID, 'Target':preds})\n",
    "prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion.to_csv('prediccion_random_forest_2', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puede tardar mucho, los valores que me habian salido para menos features fueron:\n",
    "# colsample_bytree = 0.5, \n",
    "# learning_rate = 0.1, \n",
    "# max_depth = 12, \n",
    "# alpha = 5, \n",
    "# n_estimators = 50, \n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'colsample_bytree': [0.1,0.3,0.5],\n",
    "                     'learning_rate': [0.1, 0.05],\n",
    "                     'max_depth': [5,8,10,12],\n",
    "                     'alpha': [5,10,15],\n",
    "                     'n_estimators': [10,50],\n",
    "                     'objective': ['binary:logistic'],\n",
    "                     'eval_metric': ['logloss']}]\n",
    "\n",
    "score = 'log_loss'\n",
    "print('# Tuning hyper-parameters for XGBoost and Log loss')\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(trainX, y, test_size=0.2, random_state=123)\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor()\n",
    "clf = GridSearchCV(\\\n",
    "    xgb_reg, tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\")\n",
    "print(clf.best_params_ )\n",
    "print()\n",
    "print('Best Score:')\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo el error\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(trainX, y, test_size=0.15, random_state=123)\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective = 'binary:logistic', \\\n",
    "                           colsample_bytree = 0.5, \\\n",
    "                           learning_rate = 0.1, \\\n",
    "                           max_depth = 12, \\\n",
    "                           alpha = 5, \\\n",
    "                           n_estimators = 50, \\\n",
    "                           subsample=0.5,\\\n",
    "                           eval_metric='logloss')\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "preds = xgb_reg.predict(X_test)\n",
    "ll = log_loss(y_test, preds, normalize=True)\n",
    "print(\"Log Loss: %f\" % (ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame({'feature':X_train.columns, 'value':xgb_reg.feature_importances_})\n",
    "p = p.sort_values('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcoFML_4YNWl",
    "outputId": "dbd6417d-6593-4801-b328-12dcee4de7b0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(p.feature, p.value)\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Importancia')\n",
    "plt.title('Importancia Features con XGBRegressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(objective = 'binary:logistic', \\\n",
    "                           colsample_bytree = 0.5, \\\n",
    "                           learning_rate = 0.1, \\\n",
    "                           max_depth = 12, \\\n",
    "                           alpha = 5, \\\n",
    "                           n_estimators = 50, \\\n",
    "                           eval_metric='logloss')\n",
    "\n",
    "xgb_reg.fit(trainX, y)\n",
    "preds = xgb_reg.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = pd.DataFrame({'Opportunity_ID':testX.Opportunity_ID, 'Target':preds})\n",
    "prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion.to_csv('prediccion_xgboost_7', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
